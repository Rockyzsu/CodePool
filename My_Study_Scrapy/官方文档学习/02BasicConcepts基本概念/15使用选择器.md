## 选择器
在我们抓取网络的有效数据的时候，我们需要从网页源码中提取数据。常用的库有如下。
* BeautifulSoup： 是Python程序员中非常流行的一个网页抓取库，它基于HTML代码的结构构建了一个Python对象，同时也很好地处理了糟糕的标记，但是它有一个缺点：速度慢。
* lxml： 是一个基于ElementTree的pythonic API的XML解析库（它也解析HTML）。 （lxml不是Python标准库的一部分。）

scrapy有自己的抓取框架，可以使用xpath，或者css表达式。我个人懂点前段，喜欢使用css。

引用选择器对应的包

```python
In [1]: from scrapy.selector import Selector

In [2]: from scrapy.http import HtmlResponse
```

### 从文本提取
```python
In [3]: body="<html><body><span>good</span></body></html>"

In [4]: Selector(text=body).css("span::text").extract()
Out[4]: ['good']
```

### 使用选择器

我们从官方文档这个部分看到，在获取到response的时候可以使用response.selector.xpath，也可以使用response.xpath方法提取数据的。
我们可以看到在源代码中有如下代码。
```python
    def xpath(self, query, **kwargs):
        return self.selector.xpath(query, **kwargs)
```
也就是我们直接使用response.css,response.xpath这些方法，本质还是响应流持有的选择器对象的对应方法。

我们可以使用extract,extract_first两个方法提取数据， 默认extract提取到的是列表的。
在`d:\users\administrator\anaconda3\lib\site-packages\parsel\selector.py`文件中，可以看到如下代码：
```python
    def extract(self):
        """
        Call the ``.extract()`` method for each element is this list and return
        their results flattened, as a list of unicode strings.
        """
        return [x.extract() for x in self]
    getall = extract

    def extract_first(self, default=None):
        """
        Return the result of ``.extract()`` for the first element in this list.
        If the list is empty, return the default value.
        """
        for x in self:
            return x.extract()
        else:
            return default
```
通过上面的代码， 我们可以看出来，extract和extract_first的代码几乎没太多的差别，
extract_first相当于extract()[0],但是如果在extract()没有提取的元素的时候，extract_first使用默认的none值。
建议使用extract_first，不建议使用extract()[0]这种方式。

除了使用默认的xpath和css，还是可以使用re的

```python
response.xpath('//a[contains(@href, "image")]/text()').re_first(r'Name:\s*(.*)')
u'My image 1'
```
###  Selector objects

#### xpath(query)
使用xpath方式去提取数据，返回值为SelectorList。

#### css(query)
使用css方式去提取数据，返回值为SelectorList。底层还是调用的xpath方法。
在`d:\users\administrator\anaconda3\lib\site-packages\parsel\selector.py`文件中，可以找到如下代码
```python
    def css(self, query):
        """
        Apply the given CSS selector and return a :class:`SelectorList` instance.

        ``query`` is a string containing the CSS selector to apply.

        In the background, CSS queries are translated into XPath queries using
        `cssselect`_ library and run ``.xpath()`` method.
        """
        return self.xpath(self._css2xpath(query))
```
可以看出来， 这个css方法，调用了xpath方法，需要把css的查询表达式转化为xpath的表达式。

#### extract()
提取数据

#### re(regex)
使用正则表达式去提取数据。

####  register_namespace(prefix, uri)
注册给定的命名空间在这个选择器中使用。 如果不注册名称空间，则无法从非标准名称空间中选择或提取数据。

#### remove_namespaces()
移除命名空间

#### __nonzero__()
如果选择了真实内容，则返回True，否则返回False。 换句话说，Selector的布尔值由它选择的内容给出。
